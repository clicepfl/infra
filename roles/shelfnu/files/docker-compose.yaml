# Usage
#   Start:              docker compose up
#   With helpers:       docker compose -f docker-compose.yml -f ./dev/docker-compose.dev.yml up
#   Stop:               docker compose down
#   Destroy:            docker compose -f docker-compose.yml -f ./dev/docker-compose.dev.yml down -v --remove-orphans
#   Reset everything:  ./reset.sh

services:
  shelf:
    image: ghcr.io/shelf-nu/shelf.nu:main-1a8d06c
    environment:
      DATABASE_URL: postgres://postgres:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/${POSTGRES_DB}
      DIRECT_URL: postgres://postgres:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/${POSTGRES_DB}
      SUPABASE_ANON_PUBLIC: ${ANON_KEY}
      SUPABASE_SERVICE_ROLE: ${SERVICE_ROLE_KEY}
      SESSION_SECRET: super-duper-s3cret
      SERVER_URL: https://clic.epfl.ch:7004
      SUPABASE_URL: http://kong:8000

      SMTP_HOST: mail.epfl.ch
      SMTP_PORT: 587
      SMTP_USER: it.clic
      SMTP_FROM: '"IT CLIC" <it.clic@epfl.ch>'
      SMTP_PWD: ${SMTP_IT_PASSWORD}
      
      INVITE_TOKEN_SECRET: ${INVITE_TOKEN_SECRET}
      MAPTILER_TOKEN: ${MAPTILER_TOKEN}
    ports:
      - 8020:8080

# Uncomment all this to re-enable studio
#   studio:
#     hostname: studio
#     image: supabase/studio:2025.04.21-sha-173cc56
#     healthcheck:
#       test:
#         [
#           "CMD",
#           "node",
#           "-e",
#           "fetch('http://studio:3000/api/platform/profile').then((r) => {if (r.status !== 200) throw new Error(r.status)})"
#         ]
#       timeout: 10s
#       interval: 5s
#       retries: 3
#     environment:
#       STUDIO_PG_META_URL: http://meta:8080
#       POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
#
#       DEFAULT_ORGANIZATION_NAME: clicepfl
#       DEFAULT_PROJECT_NAME: shelf-nu
#
#       SUPABASE_URL: http://kong:8000
#       SUPABASE_PUBLIC_URL: https://clic.epfl.ch:${KONG_HTTPS_PORT}
#       SUPABASE_ANON_KEY: ${ANON_KEY}
#       SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
#       AUTH_JWT_SECRET: ${JWT_SECRET}
#
#
#   meta:
#     hostname: meta
#     image: supabase/postgres-meta:v0.88.9
#     environment:
#       PG_META_PORT: 8080
#       PG_META_DB_HOST: ${POSTGRES_HOST}
#       PG_META_DB_PORT: ${POSTGRES_PORT}
#       PG_META_DB_NAME: ${POSTGRES_DB}
#       PG_META_DB_USER: supabase_admin
#       PG_META_DB_PASSWORD: ${POSTGRES_PASSWORD}


  kong:
    hostname: kong
    image: kong:2.8.1
    ports:
      - ${KONG_HTTP_PORT}:8000/tcp
    volumes:
      # https://github.com/supabase/supabase/issues/12661
      - ${VOLUMES_PATH}/api/kong.yml:/home/kong/temp.yml:ro,z
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /home/kong/kong.yml
      # https://github.com/supabase/cli/issues/14
      KONG_DNS_ORDER: LAST,A,CNAME
      KONG_PLUGINS: request-transformer,cors,key-auth,acl,basic-auth
      KONG_NGINX_PROXY_PROXY_BUFFER_SIZE: 160k
      KONG_NGINX_PROXY_PROXY_BUFFERS: 64 160k
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      # required even if the dashboard is not present
      DASHBOARD_USERNAME: ${DASHBOARD_USERNAME}
      DASHBOARD_PASSWORD: ${DASHBOARD_PASSWORD}
    # https://unix.stackexchange.com/a/294837
    entrypoint: bash -c 'eval "echo \"$$(cat ~/temp.yml)\"" > ~/kong.yml && /docker-entrypoint.sh kong docker-start'

  auth:
    hostname: auth
    image: supabase/gotrue:v2.171.0
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:9999/health",
        ]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      GOTRUE_API_HOST: 0.0.0.0
      GOTRUE_API_PORT: 9999
      API_EXTERNAL_URL: https://clic.epfl.ch:${GOTRUE_HTTPS_PORT}

      GOTRUE_DB_DRIVER: postgres
      GOTRUE_DB_DATABASE_URL: postgres://supabase_auth_admin:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_INTERNAL_PORT}/${POSTGRES_DB}

      GOTRUE_SITE_URL: https://clic.epfl.ch
      GOTRUE_DISABLE_SIGNUP: "false"

      GOTRUE_JWT_ADMIN_ROLES: service_role
      GOTRUE_JWT_AUD: authenticated
      GOTRUE_JWT_DEFAULT_GROUP_NAME: authenticated
      GOTRUE_JWT_SECRET: ${JWT_SECRET}

      GOTRUE_EXTERNAL_PHONE_ENABLED: "false"
      GOTRUE_EXTERNAL_EMAIL_ENABLED: "true"

      GOTRUE_SMTP_HOST: mail.epfl.ch
      GOTRUE_SMTP_PORT: "587"
      GOTRUE_SMTP_USER: it.clic
      GOTRUE_SMTP_PASS: ${SMTP_IT_PASSWORD}
      GOTRUE_SMTP_ADMIN_EMAIL: it.clic@epfl.ch
    ports:
      - ${GOTRUE_HTTP_PORT}:9999

  rest:
    hostname: rest
    image: postgrest/postgrest:v12.2.11
    environment:
      PGRST_DB_URI: postgres://authenticator:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_INTERNAL_PORT}/${POSTGRES_DB}
      PGRST_DB_SCHEMAS: public,storage,graphql_public
      PGRST_DB_ANON_ROLE: anon
      PGRST_JWT_SECRET: ${JWT_SECRET}
      PGRST_DB_USE_LEGACY_GUCS: "false"
      PGRST_APP_SETTINGS_JWT_SECRET: ${JWT_SECRET}
      PGRST_APP_SETTINGS_JWT_EXP: ${JWT_EXPIRY}
    command: ["postgrest"]

  realtime:
    # This container name looks inconsistent but is correct because realtime constructs tenant id by parsing the subdomain
    hostname: realtime-dev.supabase-realtime
    image: supabase/realtime:v2.34.47
    healthcheck:
      test:
        [
          "CMD",
          "curl",
          "-sSfL",
          "--head",
          "-o",
          "/dev/null",
          "-H",
          "Authorization: Bearer ${ANON_KEY}",
          "http://localhost:4000/api/tenants/realtime-dev/health",
        ]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      PORT: 4000
      DB_HOST: ${POSTGRES_HOST}
      DB_PORT: ${POSTGRES_INTERNAL_PORT}
      DB_USER: supabase_admin
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_NAME: ${POSTGRES_DB}
      DB_AFTER_CONNECT_QUERY: "SET search_path TO _realtime"
      DB_ENC_KEY: supabaserealtime
      API_JWT_SECRET: ${JWT_SECRET}
      SECRET_KEY_BASE: ${SECRET_KEY_BASE}
      ERL_AFLAGS: -proto_dist inet_tcp
      DNS_NODES: "''"
      RLIMIT_NOFILE: "10000"
      APP_NAME: realtime
      SEED_SELF_HOST: "true"
      RUN_JANITOR: "true"

  # To use S3 backed storage: docker compose -f docker-compose.yml -f docker-compose.s3.yml up
  storage:
    hostname: storage
    image: supabase/storage-api:v1.22.7
    volumes:
      - storage:/var/lib/storage
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://0.0.0.0:5000/status",
        ]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      ANON_KEY: ${ANON_KEY}
      SERVICE_KEY: ${SERVICE_ROLE_KEY}
      POSTGREST_URL: http://rest:3000
      PGRST_JWT_SECRET: ${JWT_SECRET}
      DATABASE_URL: postgres://supabase_storage_admin:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_INTERNAL_PORT}/${POSTGRES_DB}
      FILE_SIZE_LIMIT: 52428800
      STORAGE_BACKEND: file
      FILE_STORAGE_BACKEND_PATH: /var/lib/storage
      TENANT_ID: stub
      # TODO: https://github.com/supabase/storage-api/issues/55
      REGION: stub
      GLOBAL_S3_BUCKET: stub
      ENABLE_IMAGE_TRANSFORMATION: "true"
      IMGPROXY_URL: http://imgproxy:5001

  imgproxy:
    hostname: imgproxy
    image: darthsim/imgproxy:v3.8.0
    volumes:
      - storage:/var/lib/storage
    healthcheck:
      test: ["CMD", "imgproxy", "health"]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      IMGPROXY_BIND: ":5001"
      IMGPROXY_LOCAL_FILESYSTEM_ROOT: /
      IMGPROXY_USE_ETAG: "true"
      IMGPROXY_ENABLE_WEBP_DETECTION: "true"

  functions:
    hostname: functions
    image: supabase/edge-runtime:v1.67.4
    volumes:
      - functions:/home/deno/functions
    environment:
      JWT_SECRET: ${JWT_SECRET}
      SUPABASE_URL: http://kong:8000
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_ROLE_KEY: ${SERVICE_ROLE_KEY}
      SUPABASE_DB_URL: postgresql://postgres:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_INTERNAL_PORT}/${POSTGRES_DB}
      # TODO: Allow configuring VERIFY_JWT per function. This PR might help: https://github.com/supabase/cli/pull/786
      VERIFY_JWT: "false"
    command: ["start", "--main-service", "/home/deno/functions/main"]

  # Comment out everything below this point if you are using an external Postgres database
  db:
    hostname: ${POSTGRES_HOST}
    image: supabase/postgres:15.8.1.060
    volumes:
      - ${VOLUMES_PATH}/db/realtime.sql:/docker-entrypoint-initdb.d/migrations/99-realtime.sql:Z
      # Must be superuser to create event trigger
      - ${VOLUMES_PATH}/db/webhooks.sql:/docker-entrypoint-initdb.d/init-scripts/98-webhooks.sql:Z
      # Must be superuser to alter reserved role
      - ${VOLUMES_PATH}/db/roles.sql:/docker-entrypoint-initdb.d/init-scripts/99-roles.sql:Z
      # Initialize the database settings with JWT_SECRET and JWT_EXP
      - ${VOLUMES_PATH}/db/jwt.sql:/docker-entrypoint-initdb.d/init-scripts/99-jwt.sql:Z
      # PGDATA directory is persisted between restarts
      - db-data:/var/lib/postgresql/data:Z
      # Changes required for internal supabase data such as _analytics
      - ${VOLUMES_PATH}/db/_supabase.sql:/docker-entrypoint-initdb.d/migrations/97-_supabase.sql:Z
      # Changes required for Analytics support
      - ${VOLUMES_PATH}/db/logs.sql:/docker-entrypoint-initdb.d/migrations/99-logs.sql:Z
      # Changes required for Pooler support
      - ${VOLUMES_PATH}/db/pooler.sql:/docker-entrypoint-initdb.d/migrations/99-pooler.sql:Z
      # Use named volume to persist pgsodium decryption key between restarts
      - db-encryption:/etc/postgresql-custom
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres", "-h", "localhost"]
      interval: 5s
      timeout: 5s
      retries: 10
    environment:
      POSTGRES_HOST: /var/run/postgresql
      PGPORT: ${POSTGRES_INTERNAL_PORT}
      POSTGRES_PORT: ${POSTGRES_INTERNAL_PORT}
      PGPASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGDATABASE: ${POSTGRES_DB}
      POSTGRES_DB: ${POSTGRES_DB}
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXP: ${JWT_EXPIRY}
    command: [
        "postgres",
        "-c",
        "config_file=/etc/postgresql/postgresql.conf",
        "-c",
        "log_min_messages=fatal", # prevents Realtime polling queries from appearing in logs
      ]

  # Update the DATABASE_URL if you are using an external Postgres database
  supavisor:
    hostname: pooler
    image: supabase/supavisor:2.5.1
    ports:
      - ${POSTGRES_EXTERNAL_PORT}:5432
      - ${POOLER_PROXY_TRANSACTION_PORT}:6543
    volumes:
      - ${VOLUMES_PATH}/pooler/pooler.exs:/etc/pooler/pooler.exs:ro,z
    healthcheck:
      test:
        [
          "CMD",
          "curl",
          "-sSfL",
          "--head",
          "-o",
          "/dev/null",
          "http://127.0.0.1:4000/api/health",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
    environment:
      PORT: 4000
      POSTGRES_PORT: ${POSTGRES_INTERNAL_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DATABASE_URL: ecto://supabase_admin:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_INTERNAL_PORT}/_supabase
      CLUSTER_POSTGRES: "true"
      SECRET_KEY_BASE: ${SECRET_KEY_BASE}
      VAULT_ENC_KEY: ${VAULT_ENC_KEY}
      API_JWT_SECRET: ${JWT_SECRET}
      METRICS_JWT_SECRET: ${JWT_SECRET}
      REGION: local
      ERL_AFLAGS: -proto_dist inet_tcp
      POOLER_TENANT_ID: pooler
      POOLER_DEFAULT_POOL_SIZE: 20
      POOLER_MAX_CLIENT_CONN: 100
      POOLER_POOL_MODE: transaction
    command:
      [
        "/bin/sh",
        "-c",
        '/app/bin/migrate && /app/bin/supavisor eval "$$(cat /etc/pooler/pooler.exs)" && /app/bin/server',
      ]

volumes:
  db-data:
  db-encryption:
  storage:
  imgproxy:
  functions:
